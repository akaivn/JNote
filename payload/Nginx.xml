Ngxin
	What
		Nginx(engine x) 是一个高性能的和反向代理web服务器
​		它是基于Go语言遵从Apache2.0开源协议的web服务器，源码托管在GitHup上
	Why
​		其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好，能够支持高达 50,000 个并发连接数的响应
	反向代理：
		正向代理
			用户将请求委托给代理服务器后，由代理服务器将请求转发到外网（internet）接受外网的响应后再将响应转发给用户。对用户而言，你需要明确的知道代理服务器的ip地址和具体端口号。对外网来说用户的ip和信息无法得知，只能知道代理服务器的地址和信息。而正向代理就可以理解为对外隐藏用户信息，真正代理的是用户。
			
			适用场合：
				1.访问国外无法访问的网站
				2.做缓存，加速访问资源
				3.对客户端访问授权，上网进行认证 
				4.代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息
		反向代理
			反向代理就是接受来自外网（internet）的请求，途经反向代理服务器后，由 反向代理服务器接受请求后转发到内网，这个过程跟正向代理是相反的。对用户而言，根本不知道自己访问的是反向代理服务器，反向代理服务器和目标服务器是一个整体，同样的，用户也根本无需知道反向代理服务器的ip或者具体端口。反向代理真正代理的是目标服务器，对外隐藏了目标服务器的地址和信息。
			
			适用场合：
				保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网
				 负载均衡，通过反向代理服务器来优化网站的负载
	动静分离：
​		web服务器用来加载静态资源，应用服务器用来加载动态资源，这样可以使开发更加的结构化，同时方便维护资源，提高了应用服务器的性能，又减少了应用服务器的压力
		不单单是物理上的动静分离，准确的来说是将请求动静分离，有静态请求时交给web服务器来加载，有动态请求时交给应用服务器加载。
	负载均衡：
​		将请求分发到多台服务器上，以便减轻服务器的压力

	安装Nginx(Liunx)
		安装Nginx之前需要安装一些依赖
​		注意：解决xshell的zmodem文件传输不起作用的方法
			$ yum -y install lrzsz
​		1.pcre:nginx中一些正则表达式交给pcre来解析
​			前提：安装好Gcc库 命令：
	​			$ yum install gcc -y
	​			$ yum install gcc-c++ -y
​			a.进入某个文件夹后联网下载pcre	
				$ wget https://netix.dl.sourceforge.net/project/pcre/pcre/8.37/pcre-8.37.tar.gz
	​		b.解压 
				$ tar -xvf  pcre-版本.tar.gz
	​		c.进入安装包目录
				$ cd pcre-版本
	​		d.编译检查此目录
				$ ./configure
	​		e.安装
				$ make && make install
	​		f.检查安装
				$ pcre-config --version
		2.zlib
			$ yum -y install make zlib zlib-devel libtool
		3.openssl：
			$ yum -y install openssl openssl-devel
		4.Nginx
			解压
				$ tar -xvf nginx-版本.tar.gz
			预编译（检查）进入文件夹后
				$ ./configure
			安装
				$ make && make install
			启动
				$ cd /usr/local/nginx/sbin/
		  		$ ./nginx
		  	这里可能会出现lib文件找不到或无法打开，所以我们要建立软连接（找到你对应的pcre软件包的位置）
		  		$ ln -s /lib64/libpcre.so.0.0.1 /lib64/libpcre.so.1
			此时就可以使用ip地址来访问nginx了
			查看nginx进程
				$ ps -ef | grep nginx
			因为默认的linux操作系统中的防火墙开放的端口和nginx开发的80端口不一样，因此，此时访问页面会被防火墙拦截，我们要把nginx的端口配置到防火墙中，让它不再拦截
		cetenOs6
			查看开放的端口号
				$ more /etc/sysconfig/iptables
			默认没有iptables文件夹，因此随便协调命令先保存到那，它会帮我们创建那个文件夹
				$ iptables -P OUTPUT ACCEPT
			保存
				$ service iptables save
			重启防火墙
				$ service iptables restart
		开放端口
			去修改/etc/sysconfig/iptables
			$ -A INPUT -p tcp -m state --state NEW -m tcp --dport 端口号 -j ACCEPT

	nginx常用命令
		使用这些常用命令必须进入到nginx文件夹内
			/usr/local/nginx/sbin/
		1.查看当前nginx版本号
			$ ./nginx -v
		2.启动nginx服务
			$ ./nginx
		3.关闭nginx
			$ ./nginx -s stop
		4.重新加载nginx（非重启）
			$ ./nginx -s reload
	​nginx配置文件
		配置文件位置：/usr/local/nginx/conf/nginx.conf

		1.全局块
			从开头到events块中间的内容都是全局块，对nginx整体有巨大影响
			worker_processes  1;
				此配置就是决定了nginx可以承受的并发数量
		2.events块
			主要影响用户与网络的链接
			events {
	    		worker_connections  1024;
			}
			此配置就决定了nginx可以支持的最大的链接数量
		3.http块
			修改最频繁的配置文件部分
			a.http全局块
				listen       80;监听的nginx的端口号
			b.server块
	nginx反向代理实例
		I.实现效果：输入www.123.com后跳转到liunx tomcat的主页面
			1.环境搭建
				a.将tomcat解压后进入tomcat bin 目录后启动
					$ ./startup.sh
				b.查看tomcat的日志看tomcat的状态
					位置：apache-tomcat-7.0.70/logs/catalina.out
					命令：$ tail -f catalina.out
				c.开放tomcat的端口号
			2.修改hosts配置文件
				将域名与端口号映射
				linux主机ip www.123.com
			3.修改nginx配置文件
				编辑时使用i键，退出编辑按esc
				a.
					server {
				        listen       80;
				        server_name  linux主机ip;
				    }
				b.
					location / {
			            root   html;
			            #加入新的配置
			            $ proxy_pass http:127.0.0.1:8080;#tomcat的端口号和地址
			            index  index.html index.htm;
			        }
			4.退出并保存
				:wq!
			5.重载测试
		II.实现效果：
			根据不同的请求路径跳转到不同的服务器的页面中去
				访问：http:主机ip:8080/edu/
				访问：http:主机ip:8081/vod/
			环境准备：
				a.搭建两个tomcat并开启防火墙端口号
				b.准备文件夹和页面

			nginx配置文件配置
				server {
				    #    listen       8000;
				    #    listen       somename:8080;
				    #    server_name  somename  alias  another.alias;

				    #    location / {
				    #        root   html;
				    #        index  index.html index.htm;
				    #    }
				   	listen  9001;
					#监听的端口为nginx新开放的端口
					server_name ip;
					#案例实际代码配置操作
					location ~ /edu/ {
						$ proxy_pass http://127.0.0.1:8080;
					}
					location ~ /vod/ {
				        $ proxy_pass http://ip:8081;
				    }	
				}
		关闭虚拟机：shutdown -h now:现在关闭
		关闭xshell：quit
	nginx负载均衡实例
		实现效果：使两台服务器能够分摊一个请求 http://ip/kate/a.html
		a.启动两台tomcat
		b.配置nginx.conf文件

			1.配置upstream块
				upstream myserver {
			        $ server ip:8080;
			        $ server ip:8081;
			    }
			2.应用这个块
			server{
				server_name 主机ip;
				location / {
		            root   html;
		            $ proxy_pass http://myserver;
		            index  index.html index.htm;
		        }
			}
		c.nginx负载均衡策略
			I.轮询（默认）
				配置：缺省即可
				作用：将请求 按照时间的顺序来平均分摊到每个服务器上。如果后端服务器down掉，能自动剔除。 
				使用场景：此策略适合服务器配置相当，无状态且短平快的服务使用。
			II.weight（权重）
				配置:
					例：
					upstream myserver {
				        $ server ip:8080 weight = 1;
				        $ server ip:8081 weithe = 10;
			    	}
			    作用：在轮询策略的基础上指定轮询的几率。将请求按权重数字大小来让服务器分摊，数字越大分摊的请求比例越大，数字越小分摊的请求比例越小。默认值为1
			    使用场景：此策略比较适合服务器的硬件配置差别比较大的情况。
			III.ip_hash(IP绑定)
				配置：
					例：
						upstream myserver {
					        $ server ip:8080;
					        $ server ip:8081;
					        $ ip_hash;
				    	}
				作用：指定负载均衡器按照基于客户端IP的分配方式，这个方法确保了相同的客户端的请求一直发送到相同的服务器，以保证session会话。这样每个访客都固定访问一个后端服务器，可以解决session不能跨服务器的问题。
				使用场景：
					a.在nginx版本1.3.1之前，不能在ip_hash中使用权重（weight）。
					b.ip_hash不能与backup同时使用。
					c.此策略适合有状态服务，比如session。
					d.当有服务器需要剔除，必须手动down掉。
			IV.least_conn(链接较少)
				配置：
					例：
						upstream myserver {
							$ least_conn;
					        $ server ip:8080;
					        $ server ip:8081;
				    	}
				作用：把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同；但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，least_conn这种方式就可以达到更好的负载均衡效果。
				使用场景：此负载均衡策略适合请求处理时间长短不一造成服务器过载的情况。
			第三方策略：
				第三方的负载均衡策略的实现需要安装第三方插件。
				I.fair
					配置：
						例：
							upstream myserver {
						        $ server ip:8080;
						        $ server ip:8081;
						        $ fair;
				    		}
					作用：按照服务器端的响应时间来分配请求，响应时间短的优先分配。
				II.url_hash
					配置：
						例：
							upstream myserver {
								$ hash $request_uri;
						        $ server ip:8080;
						        $ server ip:8081;
						        $ fair;
				    		}
					作用：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。而使用url_hash，可以使得同一个url（也就是同一个资源请求）会到达同一台服务器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取。
	nginx动静分离实例
		实现效果：让nginx可以访问静态资源并加载
		1.创建文件（静态）
		2.配置nginx配置文件
			#将静态资源所在的文件夹告诉nginx，由他来完成对静态资源的加载
			location /htmls/ {
	            root   /data/;
	            index  index.html index.htm;
	        }
	        location /images/{
                root /data/;
                autoindex on;#将图片信息完全显示
	        }
	nginx配置高可用集群实例
	nginx原理
		原理：采用的是master(管理者)和worker(工作者)的运行机制，当有请求到达nginx服务器时，master通知worker由worker进行争抢。
		这种设计模式的好处：
			1.重载(./nginx -s reload)：当一个worker争抢到一个请求时，它去处理它的事，而其余的worker去重新加载新的nginx配置文件，再来请求，新的worker处理时，就使用的是最新的nginx配置。而当原来的worker做完事情后它再去重新的加载nginx最新的配置，可以实现即时一个worker宕掉，其余worker仍然能够正常工作。
			2.因为worker是线程独立的，每一个worker占用独立的一个线程，因此不存在锁的机制，加锁就会影响性能。当然也不会造成线程占用问题。
			3.占用独立的线程，一个down掉，其余正常工作。
		设立多少个worker合适
			Nginx 同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进 程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话 下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。所以 worker 数和服务器的 cpu 数相等是最为适宜的。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的损耗
		如何设置worker数量
			几核设置几个
			#work 绑定 cpu(4 work 绑定 4cpu)
				worker_cpu_affinity 0001 0010 0100 1000 
		每个请求占用一个worker的几个链接
			2个(处理静态资源)或者4个(通过tomcat处理动态资源或者查询数据库)
		每个worker支持的最大的并发链接数量
			公式：worker_connection * worker_processes / 2 | 4
			解析：nginx最大的连接数量/2(静态请求)或者/4(用nginx做反向代理)

	Docker数据文件挂载+启动命令
	$ 	docker run -d -p 80:80 --name nginxtcl -v /data/nginx/conf:/etc/nginx/conf -v /data/nginx/nginx.conf:/etc/nginx/nginx.conf nginx